{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "import pickle\n",
    "\n",
    "RESCALE_SIZE = (120, 100)\n",
    "\n",
    "\n",
    "class ZenseactSSLDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.roadcondition = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dat = self.data[idx]\n",
    "        if self.transform:\n",
    "            dat = self.transform(dat)\n",
    "        dummy_label = 0\n",
    "        return dat, dummy_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "class ZenseactMetadata(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta_dat = self.data[idx]\n",
    "        return meta_dat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, num_views):\n",
    "        self.base_transform = base_transform\n",
    "        self.num_views = num_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = [self.base_transform(x)]\n",
    "        views = []\n",
    "        for view in range(self.num_views):\n",
    "            view = self.base_transform(x)\n",
    "            views.append(view)\n",
    "        return [q, views]\n",
    "    \n",
    "\n",
    "def generate_ssl_data(size=25_000):\n",
    "    parent_directory = \"../../../mnt/nfs_mount/single_frames\"\n",
    "\n",
    "    # Find all folders with a 6-digit name\n",
    "    folder_pattern = os.path.join(parent_directory, \"[0-9]\" * 6)\n",
    "\n",
    "    # Get the list of matching folders\n",
    "    folders = glob.glob(folder_pattern)\n",
    "    folders = folders[0:size] # *size* folders\n",
    "\n",
    "    image_data = []\n",
    "    for folder in folders:\n",
    "        id = os.path.basename(folder) # id = foldername\n",
    "        # load image\n",
    "        image_path = f\"../../../mnt/nfs_mount/single_frames/{id}/camera_front_blur/\"\n",
    "        image_path = glob.glob(image_path + \"*.jpg\")\n",
    "        image = Image.open(image_path[0]).convert('RGB')\n",
    "        # resize image\n",
    "        downsampled_image = image.resize(RESCALE_SIZE)\n",
    "\n",
    "        image_data.append(downsampled_image)\n",
    "        \n",
    "    return image_data\n",
    "\n",
    "\n",
    "def generate_noniid_ssl_data(size=25_000):\n",
    "    parent_directory = \"../../../mnt/nfs_mount/single_frames\"\n",
    "\n",
    "    # Find all folders with a 6-digit name\n",
    "    folder_pattern = os.path.join(parent_directory, \"[0-9]\" * 6)\n",
    "\n",
    "    # Get the list of matching folders\n",
    "    folders = glob.glob(folder_pattern)\n",
    "    folders = folders[0:size] # *size* folders\n",
    "\n",
    "    meta_data = []\n",
    "    for folder in folders:\n",
    "        id = os.path.basename(folder) # id = foldername\n",
    "        # metainformation\n",
    "        metadata = f\"../../../mnt/nfs_mount/single_frames/{id}/metadata.json\"\n",
    "        f = open(metadata)\n",
    "        metadata = json.load(f)\n",
    "        weather_condition = metadata[\"scraped_weather\"]\n",
    "        meta_data.append(weather_condition)\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = generate_noniid_ssl_data(25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dict = {}\n",
    "for data in meta_data:\n",
    "    if data not in sum_dict:\n",
    "        sum_dict[data] = 1\n",
    "    else:\n",
    "        sum_dict[data] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'partly-cloudy-day': 8535,\n",
       " 'cloudy': 5099,\n",
       " 'clear-day': 3737,\n",
       " 'rain': 4491,\n",
       " 'clear-night': 554,\n",
       " 'snow': 436,\n",
       " 'partly-cloudy-night': 1874,\n",
       " 'wind': 36,\n",
       " 'fog': 238}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file found\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"ssl_data.pkl\"):\n",
    "        print(\"data file found\")\n",
    "        with open(\"ssl_data.pkl\", \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "else:\n",
    "    print(\"generating data. This might take a while.\")\n",
    "    data = generate_ssl_data(25_000)\n",
    "    with open(\"ssl_data.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zenseactmetadata = ZenseactMetadata(meta_data)\n",
    "zenseactssldataset = ZenseactSSLDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "num_data_per_client = len(zenseactssldataset) // num_clients\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [],\n",
       " '2': [],\n",
       " '3': [],\n",
       " '4': [],\n",
       " '5': [],\n",
       " '6': [],\n",
       " '7': [],\n",
       " '8': [],\n",
       " '9': [],\n",
       " '10': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_indices = {}\n",
    "\n",
    "for i in range(num_clients):\n",
    "    client_indices[str(i+1)] = []\n",
    "client_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_per_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index(client_num, index):\n",
    "    if client_num > num_clients:\n",
    "        return\n",
    "    elif len(client_indices[str(client_num)]) >= num_data_per_client:\n",
    "        add_index(client_num+1, index)\n",
    "    else:\n",
    "        client_indices[str(client_num)].append(index)\n",
    "\n",
    "for i in range(len(zenseactmetadata)):\n",
    "    weather = zenseactmetadata[i]\n",
    "    if weather == \"partly-cloudy-day\":\n",
    "        add_index(1, i)\n",
    "    elif weather == \"cloudy\":\n",
    "        add_index(2, i)\n",
    "    elif weather == \"clear-day\":\n",
    "        add_index(3, i)\n",
    "    elif weather == \"rain\":\n",
    "        add_index(4, i)\n",
    "    elif weather == \"clear-night\":\n",
    "        add_index(5, i)\n",
    "    elif weather == \"snow\":\n",
    "        add_index(6, i)\n",
    "    elif weather == \"partly-cloudy-night\":\n",
    "        add_index(7, i)\n",
    "    elif weather == \"fog\":\n",
    "        add_index(8, i)\n",
    "    else:\n",
    "        add_index(9, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7fc50183d090>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc50212b0a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc5021299c0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc50212b700>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502129e70>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc50212b190>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502138cd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502139ff0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502139000>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502138430>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_dataloaders = []\n",
    "for client, indices in client_indices.items():\n",
    "    local_datasets = Subset(zenseactssldataset, indices)\n",
    "    local_dataloaders.append(DataLoader(local_datasets, batch_size=batch_size))\n",
    "\n",
    "local_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zenseactmetadata = ZenseactMetadata(meta_data)\n",
    "zenseactssldataset = ZenseactSSLDataset(data)\n",
    "\n",
    "def load_data_noniid(zenseactssldataset, zenseactmetadata, num_clients, batch_size):\n",
    "    num_data_per_client = len(zenseactssldataset) // num_clients\n",
    "    \n",
    "    client_indices = {}\n",
    "    for i in range(num_clients):\n",
    "        client_indices[str(i+1)] = []\n",
    "\n",
    "    def add_index(client_num, index):\n",
    "        if client_num > num_clients:\n",
    "            return\n",
    "        elif len(client_indices[str(client_num)]) >= num_data_per_client:\n",
    "            add_index(client_num+1, index)\n",
    "        else:\n",
    "            client_indices[str(client_num)].append(index)\n",
    "\n",
    "    for i in range(len(zenseactmetadata)):\n",
    "        weather = zenseactmetadata[i]\n",
    "        if weather == \"partly-cloudy-day\":\n",
    "            add_index(1, i)\n",
    "        elif weather == \"cloudy\":\n",
    "            add_index(2, i)\n",
    "        elif weather == \"clear-day\":\n",
    "            add_index(3, i)\n",
    "        elif weather == \"rain\":\n",
    "            add_index(4, i)\n",
    "        elif weather == \"clear-night\":\n",
    "            add_index(5, i)\n",
    "        elif weather == \"snow\":\n",
    "            add_index(6, i)\n",
    "        elif weather == \"partly-cloudy-night\":\n",
    "            add_index(7, i)\n",
    "        elif weather == \"fog\":\n",
    "            add_index(8, i)\n",
    "        else:\n",
    "            add_index(9, i)\n",
    "\n",
    "    local_dataloaders = []\n",
    "    for client, indices in client_indices.items():\n",
    "        local_datasets = Subset(zenseactssldataset, indices)\n",
    "        local_dataloaders.append(DataLoader(local_datasets, batch_size=batch_size))\n",
    "\n",
    "    return local_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7fc5d67a73d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc5021707c0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc5021735e0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502173730>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502173af0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502173c70>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc5021733d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502172f80>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc502172050>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc5021720b0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_noniid(zenseactssldataset, zenseactmetadata, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
